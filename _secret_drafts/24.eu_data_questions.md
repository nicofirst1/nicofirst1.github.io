---
title: "Mapping the EU AI Landscape (Part 3): Can you Train on my Data?"
slug: data-strategy-questions
tag: BlogPost
image: /assets/images/news/eu_landscape/eu_landscape_p3.png
date: 2024.10.23
---


# Intro


Let me ask you a question (or a few). Let's imagine you are a business, or even more general, you are in an EU project that is using data for, let's say, training a LLM. Do you know :
1. How to you handle Personal Identification Information (PII) in your data? 
2. What about licensed and copyrighted material?  
   - Both the DGA and Data actexplicitly state that they do not affect existing intellectual property rights (IPR) and these are dependent on existing laws, which ones?
3. If you plan to release your data, which format do you need to use? What kind of metadata are sufficent? 
   - The Data act only states that format must be machine readable (no paper basically) and "commonly used".
   - Metadata on the other hand has to be "relevant" and "necessary to interpret use". It is also specified that this metaata needs to include description of the data structure, format, vocabularies (?) and access mechanism. 
4. What the hell are data spaces?


While I cannot tell the specific answers to these problem, we can still infer where they might be (it feels like a treasure hunt at this point).

1. Ansers to PII are definetly in the [GDPR](https://gdpr-info.eu/) and maybe in the AI ACT
2. IPR are probably either [on the Euripean IP helpdesk](https://intellectual-property-helpdesk.ec.europa.eu/regional-helpdesks/european-ip-helpdesk_en) or [here](https://europa.eu/youreurope/business/running-business/intellectual-property/rights/index_en.htm#:~:text=If%20you%20protect%20your%20invention,and%20its%20origin%20is%20clear.) 
3. Metadata... maybe finding out more about [INSPIRE](https://knowledge-base.inspire.ec.europa.eu/index_en) or the EDIB would be a good starting point
4. Data spaces are [here](https://digital-strategy.ec.europa.eu/en/policies/data-spaces) 

You know what this mean?
We are not done yet!



# Answering Questions
## AI, Data and PII

The first thing we are interested in is to find out how to handle data with PII. To this end we need to check both in the AI act and GDPR.

### Use of personal data for AI 


By looking for the key word "personal data" in the AI act we are given these (and many other ignored) matches..
Most of the relevant one refer to the GDPR (Regulation (EU) 2016/679), [New Data Protection Framework](https://eur-lex.europa.eu/eli/reg/2018/1725/oj) (Regulation (EU) 2018/1725) and the [Law Enforcment Directive](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32016L0680) (Directive (EU) 2016/680). 

- Article 1:
  - Point 10[^15] : The fundamental righs to data protection from the GDPR still applies. 
  - Point 67[^16]:  You should always mention how and where you got your data.
  - Point 69 [^17]: You should follow the principles of **data minimisation and protection** defined in the GDPR. Also you should ate least anonymise and encrypt the data you are using, better if you don't even access the data, but transfer your algorithm to where the data is located. This seems to be a pretty solid reference to federated learning. 
  - Point 140 : Talks about data sandboxes, and says how you can use personal data collected for other purposes in your ai system only in accordance with various articles [^18]
- Article 10 is all about data governance and includes a number of musts if you are working with data[^19]
- Article 59 is all about personal data in data sandboxoes. Basically if you are in a data sandbox you are allowed to process "lawfully" gathered personal data only if you are doing healthcare, enironment, transport or efficiency of public sectors. Also you have to delete the data once you used it.


To summarize, you should always psydo/ananymize personal data, and in the reare cases when you don't you have to show that you need the personal data for mitigating biases.


[^15]: The fundamental right to the protection of personal data is safeguarded in particular by Regulations (EU) 2016/679 and (EU) 2018/1725 of the European Parliament and of the Council and Directive (EU) 2016/680 of the European Parliament and of the Council13

[^16]: In order to facilitate compliance with Union data protection law, such as Regulation (EU) 2016/679, data governance and management practices should include, in the case of personal data, transparency about the original purpose of the data collection

[^17]: The right to privacy and to protection of personal data must be guaranteed throughout the entire lifecycle of the AI system. In this regard, the principles of data minimisation and data protection by design and by default, as set out in Union data protection law, are applicable when personal data are processed. Measures taken by providers to ensure compliance with those principles may include not only anonymisation and encryption, but also the use of technology that permits algorithms to be brought to the data and allows training of AI systems without the transmission between parties or copying of the raw or structured data themselves, without prejudice to the requirements on data governance provided for in this Regulation.


[^18]: The statement refers to the following articles: (i) **Article 6(4) GDPR**: This article deals with the legal basis for processing personal data, requiring that processing be "necessary for compliance with a legal obligation to which the controller is subject." This emphasizes that any processing of personal data for law enforcement or judicial cooperation purposes must have a solid legal basis under EU or Member State law. (ii) **Article 9(2)(g) GDPR**: This provision concerns the processing of special categories of personal data, which are considered more sensitive and require higher levels of protection. Point (g) specifically allows processing such data when "necessary for reasons of substantial public interest, on the basis of Union or Member State law which shall be proportionate to the aim pursued." This is relevant because law enforcement activities often involve sensitive data like criminal records or biometric information. (iii) **Articles 5, 6, and 10 of Regulation (EU) 2018/1725**: These articles mirror the principles of lawfulness, fairness, and transparency in data processing, the legal basis for processing, and limitations on processing sensitive data, respectively, as outlined in the GDPR. Their inclusion emphasizes that these principles also apply to EU institutions and bodies, ensuring consistent data protection standards. (iv) **Article 4(2) and Article 10 of Directive (EU) 2016/680**: While not explicitly stated, the reference to these articles without prejudice suggests that the statement does not intend to limit or restrict the application of these provisions. Article 4(2) defines "competent authority," which is crucial for determining which entities are subject to the directive's rules. Article 10 deals with data protection principles, requiring that processing be "necessary and proportionate" and carried out "with due regard for the legitimate interests of the data subject." This reinforces the need for a balanced approach that protects both individual rights and law enforcement needs.

[^19]: Among the musts we can see: (2.b) alwasy discole where your data came from and how you collected it; (2.c) how you processed your data before use; (2.d) formulate assumption in respect of what you expect to find in your data; (2.f) examine possible biases; (2.g) given the biases you are suspecting to find implement measure to detect and mitigate them; (4) data should be geographical, contextual and behavirousal appropriate for the intended purpose (aka if you want an LMM for eu, don't train it on american data only); (5) if you really cannot do anything for biases with your current data you are exceptionally allowed to process other categories of personal data; (5.c) in this case you have to document who has access to the data; (5.d) you cannot transfer them and (5.c) you have to detele them once you're done.


#### Data Features

Point 67 of Article 1 mentioned the priciple of "data minimisation and protection", what are we talking about? Also, according to article 66 in the AI act, data should also be of "high-quality" (what does that even mean).
In general, the data used for ai has to have a set of features or adhere to some pricinples. 

##### Principle of Data Minimisation

The EU data protection supervisor [defines](https://www.edps.europa.eu/data-protection/data-protection/glossary/d_en#:~:text=The%20principle%20of%20%E2%80%9Cdata%20minimisation,necessary%20to%20fulfil%20that%20purpose.) the principle of *data minimisation* to be "data controllers should collect only the personal data they really need, and should keep it only for as long as they need it.". 
Working with large quantities of data myself, the question of "how much data is enough" often pops out. In th scope of training language modeles, it seems that no data is enought. This would imply that, as long as you're doing llms, you don't really need to agree to this principle and you can collect all the data available on the internet. 
If we also take into account Article 10 point 5 of the AI Act, which says that you can collect personal informatino in the cases where you need it to reduce bias, we can find a loopwhole where we can access personal data in enourmous quantitiies, wihtout anonymized all for the purpose of diminishng biases in LLMs training[^20]


[^20]: However, recent studies ([Dong et al. 2024](https://www.semanticscholar.org/paper/Disclosure-and-Mitigation-of-Gender-Bias-in-LLMs-Dong-Wang/8a515a6510e209f1ab9e53d70c291c7e007716d5) and [Huang et al. 2023](https://www.semanticscholar.org/paper/Bias-Testing-and-Mitigation-in-LLM-based-Code-Huang-Bu/148134fac202889ff6256b6b7d574cb714941887)) have showen that increasing the quantity of data is not the most effective technique for bias mitigation.


##### High-quality Data
At work, we recently published [an article](https://arxiv.org/abs/2410.08800) on how we process data for one of our projects. In the article we also discuss how the field does not have a standard definition of high-quality and various techiniqes are emerging around different proprieties of the text. To this end, it surprised me when i read about high-quality data in the AI-Act. Reading trhough, i noticed that the definitons are indeed pretty generic and they revolve around the concept of:

- **Biases**: we talked about this alreday. The one thing we can add on this point is that the ai act ackoleges the problem of feedback loops where biased data lead to bias models that create more biased data, feeding the loop (Point 67)
- **Relevance and Representativeness**: High-quality data should be relevant to the AI system's intended purpose and sufficiently representative of the real-world scenarios the system is expected to operate in. You could argue that if you're trying to build artificial genreal intellicenge all data is relevant. 
- **Error-Free and Complete**: I don't even know how to interpret this from a techincal prospective. What is an error in a text? A grammatical mistake? A syntatic error? A conspiracy theory (non-factual)? At least this requirement is preceded by "to the best extent possible" (article 10 point h).
- **Appropriate Statistical Properties** (again article 10 point h): another very generic point. **However** If you manage to define a statistical propriety to be a "quality signal" (e.g. factual correcteness, average word lenght, toxic content), then you would be able to define actual numbers for each of this signals. 


### Back to PII
This section was about PII, did you forget? I certaly did and had to reread from the start.

So, did we managed to find an anwer to how handle PII in your data?  Actually yes. 

You should always anonymise your data! Deleting PII in text is an active field of research right[^21] now with some enstablished methodologies. 
In addition, if you really want to be a pro-player, considere never accessing the data, and instead using a [federated approach](https://research.ibm.com/blog/what-is-federated-learning) (wink wink [GaiaX](https://gaia-x.eu/)). 

Finally, if you did nothing of what we just talked about, just mention the fact that you need PII and all this data to mitigate biases! While recent literature will probably prove you wrong, you can try to spin it to take into account some [scailng law](https://arxiv.org/abs/2402.17193). 

[^21]: Look for "de-indentification" on [google scholar](https://scholar.google.com/).



## Copyright and Intellectual propriety

So, one question down a few more to go. Let's take a look at copyright and intellectual propriety now. 

What are we interested here? 
In the scope of AI system i would say we want to know: 
1. If I train a system on copyrighted material (let's say copyright that include non commercial clauses), can i then use the system for commercial purposes?
2. What about intellectual propriety. If my model copies the input data, who's propriety is that? if it gets modified? how much should it be different from the initial data to not be IP anymore?


### Train on Copyrighted Material 

So, let's dive into the AI Act and clear up some copyright confusion, shall we? You might think, “Hey, I’m doing AI research, I can use whatever data I want, right?” Well, for research purposes, you’re generally safe—you can train on pretty much anything. But, if you're working on something for commercial purposes, things get trickier.

#### Opting Out of AI Training

If you’re training a model for commercial use, Point 105 of the AI Act tells us you need to check if the data owner **specifically** says, "Hey, don’t use this for AI". If they don’t say anything, or fail to mention it explicitly, you’re in the clear to use that data. But if they have thrown in a clear “no AI training” clause, you’d better back off.

Now, how do owners opt out of having their data fed into your AI machine? Well, the Act doesn't exactly spell it out clearly, but Point 106 gives us a clue: the EU says it’s on **you**, the AI provider, to identify and respect any copyright reservations. Fun, right?

So, how does a data owner tell the world they don’t want their stuff used in AI training? Good question. The AI Act suggests a  **Machine-readable formats** (for online content):  Embedding specific tags or codes within the data that signal the reservation of rights or maybe Including clear and explicit clauses on a website or service prohibiting TDM for AI training.


#### Whose Job Is This, Anyway?

Here’s where it gets fun: the EU puts the responsibility on **AI providers** to **figure out** if the data is off-limits (point 106). You’re expected to use “state-of-the-art technology” to spot any copyright warnings. No pressure, right?

But here’s a key point: if the data hasn’t been marked as “do not train on this” in a proper way (like machine-readable tags), it doesn’t mean copyright magically disappears. It just means you’re free to use it **unless** the owner opts out. Copyright still exists, but the rules let you proceed if nobody says otherwise.

#### Summary:

- **Check before you train**: If you’re working on a commercial AI, it’s on you to make sure the data is free to use. Look for opt-out tags or warnings.
- **Opting out is possible**: Data owners can make it clear their data is off-limits with metadata, terms, contracts, or even public statements.
- **Stay responsible**: The EU wants a balance between innovation and protecting rights, so don’t think you can ignore these rules and use everything freely.

And, just to keep things safe: **always seek proper legal advice** if you’re unsure about the specifics.

### Derivate works

This one is hard. you know why? Because it goes in the philosophical domain. 
What if i copyright this blogpost with no derivate work?  what does this even mean?

#### The Blurry Line of Similarity: No Universal Rules

When it comes to determining what’s too similar or derivative, the lines are anything but clear. Copyright and trademark laws don’t follow universal rules—it all depends on context, interpretation, and, often, a court’s judgment.

For example, let’s look at some cases that explored this gray area:

- DC Comics vs. Gotham Garage (2015): DC Comics sued a car manufacturer [for creating replicas of the Batmobile](https://www.hollywoodreporter.com/business/business-news/batmobile-lawsuit-warner-bros-wins-419661/). Although the Batmobile is "just a car", the court ruled it was a protected character due to its unique design and connection to Batman’s world. This shows that even vehicles can be characters under copyright law when they are distinctive enough.

- [Universal vs. Nintendo (1982)](https://en.wikipedia.org/wiki/Universal_City_Studios,_Inc._v._Nintendo_Co.,_Ltd.): Universal claimed Nintendo’s Donkey Kong was too similar to King Kong. However, the court sided with Nintendo, ruling that the broad idea of a giant ape was public domain, and Donkey Kong was distinct in its own way. Here, the court acknowledged similar themes, but differences in characterization and execution allowed Nintendo to win.

- [Mattel vs. MGA Entertainment (2011)](https://www.latimes.com/business/la-xpm-2011-aug-05-la-fi-mattel-bratz-20110805-story.html): Mattel, the maker of Barbie, sued MGA, claiming the Bratz dolls were derivative of Barbie. After years of litigation, the court ruled in favor of MGA, noting that while the two products shared similarities as fashion dolls, the distinctive style and design of Bratz dolls made them original enough. The case highlighted how styling and branding can create separation, even within similar categories of products.

In each case, there’s no universal rule for what’s considered "too similar". Courts look at key characteristics, overall design, and whether the new work transforms or borrows too much from the original. 
What does this mean for our AI model? The anwer is that I don't know and neither does anyone else[^21].


[^21]: There are various court cases open: [Sarah Andersen et al. vs. Stability AI, Midjourney, and DeviantArt (2023)](https://www.loeb.com/en/insights/publications/2023/11/andersen-v-stability-ai-ltd), [Getty Images vs. Stability AI (2023)](https://www.pinsentmasons.com/out-law/analysis/getty-images-v-stability-ai-implications-copyright-law-licensing), [Artists Against OpenAI's DALL-E](https://www.businessinsider.com/openai-dalle-opt-out-process-artists-enraging-2023-9).

### Summary
So what does this mean for AI? We can say for certain that if your ai system is spitting out the exact same input data, then you will defenetly get sued for copyright infringement.
For everything else, we'll have to wait. 

## Metadata 
Finally, we reached the last point. 
Here we are wondering how you should structure your metadata when releaseing a dataset. 

By looking at the AI ACT we get two general directions, your metadata has to be:
- Metadata should provide a clear explanation of how the data is organized, including the relationships between different data elements (point 23)
- You shold specify the format of your data in the metadata (point 24)

# next
- common European Data Spaces
- Data Spaces Support Centre 

# Hours worked on this
4
8 
1
4

# Footnotes