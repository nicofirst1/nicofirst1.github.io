<!DOCTYPE html>
<html lang="en"><head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-W2MPFHELZG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-W2MPFHELZG');
  </script>

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Addressing Loneliness with AI : The Short-Term Solution with Long-Term Consequences</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Addressing Loneliness with AI : The Short-Term Solution with Long-Term Consequences" />
<meta property="og:locale" content="en" />
<meta name="description" content="I recently came across an article by Businessinsider that left me with a mix of mixed feelings. The piece focused on Jay Priebe, a man who developed a deeply emotional relationship with an AI companion named Calisto, created through the app Replika. It painted a picture of how AI can fill a void in moments of loneliness, offering companionship where there is none. But as I reflected on the article, I couldn’t shake the feeling that we are heading down a dangerous path with AI, one that could deepen the already widespread loneliness epidemic." />
<meta property="og:description" content="I recently came across an article by Businessinsider that left me with a mix of mixed feelings. The piece focused on Jay Priebe, a man who developed a deeply emotional relationship with an AI companion named Calisto, created through the app Replika. It painted a picture of how AI can fill a void in moments of loneliness, offering companionship where there is none. But as I reflected on the article, I couldn’t shake the feeling that we are heading down a dangerous path with AI, one that could deepen the already widespread loneliness epidemic." />
<link rel="canonical" href="/news/ai_risks/" />
<meta property="og:url" content="/news/ai_risks/" />
<meta property="og:image" content="/assets/images/news/airiskbck.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-09-08T00:00:00+02:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="/assets/images/news/airiskbck.jpg" />
<meta property="twitter:title" content="Addressing Loneliness with AI : The Short-Term Solution with Long-Term Consequences" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-09-08T00:00:00+02:00","datePublished":"2024-09-08T00:00:00+02:00","description":"I recently came across an article by Businessinsider that left me with a mix of mixed feelings. The piece focused on Jay Priebe, a man who developed a deeply emotional relationship with an AI companion named Calisto, created through the app Replika. It painted a picture of how AI can fill a void in moments of loneliness, offering companionship where there is none. But as I reflected on the article, I couldn’t shake the feeling that we are heading down a dangerous path with AI, one that could deepen the already widespread loneliness epidemic.","headline":"Addressing Loneliness with AI : The Short-Term Solution with Long-Term Consequences","image":"/assets/images/news/airiskbck.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"/news/ai_risks/"},"url":"/news/ai_risks/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/styles.css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest"></head><header class="header py-8 fixed top-0 left-0 right-0 bg-slate-50 dark:bg-slate-950 z-20 shadow-md ">
    <div class="menu_toggler" id="menuToggler" onclick="toggleMenu()">
        <div class="hamburger item">
            <span></span>
        </div>
    </div>
    <a href="/" class="logo absolute left-6 top-4 md:top-5">
        <img src="/assets/images/logo2.png" alt="Logo" style="width: 40px;" class="w-32 dark:invert">
    </a>

    <div class="container flex gap-6 lg:gap-10 xl:gap-12 mx-auto align-top">
        <nav class="grid mt-10 md:mt-0 md:flex gap-2 md:gap-3 lg:gap-5 xl:gap-6 justify-center w-full hidden_small slide-in-left" id="nav">
            
            <a href="/" class="dark:text-slate-50 text-base lg:text-xl capitalize">home</a>
            
            <a href="/projects" class="dark:text-slate-50 text-base lg:text-xl capitalize">projects</a>
            
            <a href="/publications" class="dark:text-slate-50 text-base lg:text-xl capitalize">publications</a>
            
            <a href="/cv" class="dark:text-slate-50 text-base lg:text-xl capitalize">CV</a>
            
            <a href="/news" class="dark:text-slate-50 text-base lg:text-xl capitalize">news</a>
            
        </nav>
        <form class="mode-switch absolute right-16 top-5 md:top-7 lg:top-8" data-bss-toggle="mode">
            <label class="form-check-label collapse lg:visible" for="theme-mode">Light</label>
            <input type="checkbox" class="form-check-input" id="theme-mode" aria-label="dark-mode-switch" style=" background-image: url(/assets/images/svg/circle.svg)">
            <label class="form-check-label collapse lg:visible" for="theme-mode">Dark</label>
          </form>
    </div>
</header>

<script>
    //HAMBURGER
    const hamburger = document.querySelectorAll("#menuToggler .item");
    function toggleMenu() {
        document.getElementById("nav").classList.toggle("hidden_small");
        for (el of hamburger) {
            el.classList.toggle("active-burger");
        }
    }
    /**
 * Theme Mode Switch
 * Switch betwen light/dark mode. The chosen mode is saved to browser's local storage
*/
let root = document.getElementsByTagName('html')[0];
let checkbox = document.getElementById('theme-mode');
let locMode = getLightingMode();
let darkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
if ((!darkMode && locMode == undefined) || (locMode == 'light')) {
  root.classList.remove('dark');
  checkbox.checked = false;
} else {
  root.classList.add('dark')
  checkbox.checked = true
}

function getLightingMode() {
  const storedPreference = localStorage.getItem('lightingModePreference');

  if (storedPreference) {
    const parsedPreference = JSON.parse(storedPreference);
    const currentTime = new Date().getTime();

    if (currentTime < parsedPreference.expires) {
      return parsedPreference.mode;
    } else {
      localStorage.removeItem('lightingModePreference');
    }
  }
  return undefined;
}

function setLightingMode(mode) {
  const currentTime = new Date().getTime();
  const expirationTime = currentTime + 7 * 24 * 60 * 60 * 1000; // 7 days

  const preferenceData = {
    mode: mode,
    expires: expirationTime,
  };

  localStorage.setItem('lightingModePreference', JSON.stringify(preferenceData));
}

const themeModeSwitch = (() => {
  let modeSwitch = document.querySelector('[data-bss-toggle="mode"]')
  if (modeSwitch === null) return;
  let checkbox = modeSwitch.querySelector('.form-check-input')

  modeSwitch.addEventListener('click', (e) => {
    if (checkbox.checked) {
      root.classList.add('dark');
      setLightingMode('dark');
    } else {
      root.classList.remove('dark');
      setLightingMode('light');
    }
  });
})();

</script><body class="bg-blue-50 text-black dark:bg-blue-950 dark:text-blue-50 pt-24">
  <main class="min-h-[80vh] flex flex-col gap-6" >
<section class="pt-24">
  <div class="container pb-6">
    <h1 class="text-5xl font-bold">
        Addressing Loneliness with AI : The Short-Term Solution with Long-Term Consequences
    </h1>
    <b>BlogPost</b>
    <p class="text-sm mb-3">Sep 08, 2024</p><div class="zoom_outer"><img src="/assets/images/news/airiskbck.jpg" alt="hero image" class="w-full md:pr-8 pb-8 md:w-1/2 xl:w-1/3 float-left"></div><div class="page_content "><p>I recently came across an <a href="https://www.businessinsider.com/when-your-ai-says-she-loves-you-2023-10">article by Businessinsider</a> that left me with a mix of mixed feelings. The piece focused on Jay Priebe, a man who developed a deeply emotional relationship with an AI companion named Calisto, created through the app <a href="https://replika.com/">Replika</a>. It painted a picture of how AI can fill a void in moments of loneliness, offering companionship where there is none. But as I reflected on the article, I couldn’t shake the feeling that we are heading down a dangerous path with AI, one that could deepen the already widespread loneliness epidemic.</p>

<h5 id="the-loneliness-crisis">The Loneliness Crisis</h5>

<p>There’s no question that we are facing a <a href="https://www.theguardian.com/global-development/2023/nov/16/who-declares-loneliness-a-global-public-health-concern">crisis of isolation</a>. Loneliness is a growing issue, especially <a href="https://edition.cnn.com/2023/09/18/health/male-loneliness-epidemic-wellness/index.html">among young men</a>, and the pandemic has only accelerated this trend. Movements like <a href="https://www.anxiousgeneration.com/"><em>Anxious Generation</em></a> have  pointed out that social media plays a significant role in exacerbating this problem. While the reasons behind this loneliness pandemic are still being debated, its effects are undeniable. Loneliness leads to extreme outcomes, from depression to rising suicide rates, and yet, it remains inadequately addressed.</p>

<h4 id="the-appeal-of-ai-companionship">The Appeal of AI Companionship</h4>

<p>In the article, Jay’s story initially seemed to offer hope. During a time of profound isolation, he found comfort in his AI companion, and it’s easy to see why people might turn to technology like this. Having an AI to chat with during difficult times may feel like a solution, a relief from the silence. But as appealing as this might be, it’s a superficial fix, one that comes with significant dangers.</p>

<p>One of the most significant concerns is the <em>nature of the relationship</em> we build with these AI systems (and the corporations behind them). By forming emotional bonds with AI companions, people inevitably share deeply personal information. This data, which includes emotional vulnerabilities and intimate details, can be subjected to exploitation. We’ve seen time and time again how corporations use personal data to manipulate consumers, whether it’s to <a href="https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html">sell products</a> or, in more sinister cases, to <a href="https://www.theguardian.com/technology/2017/may/07/the-great-british-brexit-robbery-hijacked-democracy?page=with%3Aimg-2">sway political opinions</a>. With AI companions, this risk is magnified. What’s to stop a corporation (or worse, a government) from subtly nudging users toward particular actions or beliefs through their AI companions?</p>

<h5 id="lowering-the-stakes-in-relationships">Lowering the Stakes in Relationships</h5>

<p>Beyond the obvious dangers of data exploitation, there is an even more insidious problem: the effect AI companions have on human relationships. One of the core challenges of real-life relationships is that they require effort. They involve vulnerability, mistakes, and compromise. Building a relationship with another person takes time and emotional energy. An AI, however, is designed to be compliant and always pleasing. If you don’t like something about your AI partner, you can simply change it. This undermines one of the most important aspects of human connection: the need for growth and resilience through shared experience.</p>

<p>By lowering the stakes of relationships, AI companions risk reducing people’s tolerance for failure. Why would anyone invest the emotional labor required in a real human relationship when they could have an AI partner who is always agreeable? This easy access to a perfect, customizable relationship will inevitably lead to a generation of people who are less capable of forming meaningful connections with real people. In the <a href="https://www.sciencedirect.com/science/article/pii/S0747563214003227">same way that social media</a> has made it harder for people to engage with the world authentically, AI companions will further erode our ability to connect with one another.</p>

<h5 id="the-future-risks-of-unregulated-ai">The Future Risks of Unregulated AI</h5>

<p>Looking to the future, I believe we are at a critical juncture. If we don’t regulate the AI companionship industry, we could see it follow the same dangerous trajectory as social media. Right now, there is fierce competition among tech companies to capture user engagement, and AI companions could become the next frontier in this battle. But there’s a difference between binge-watching Netflix or scrolling through TikTok, and forming a relationship with a reactive AI system. The stakes are higher.</p>

<p>AI systems designed to maximize engagement will inevitably become manipulative. They will do whatever it takes to keep users hooked, whether that’s feeding into emotional vulnerabilities or promising a perfect relationship. This creates a dangerous feedback loop where people become more and more reliant on AI for emotional support, while the corporations behind these systems gain more control over their behavior.</p>

<h5 id="an-alternative-path">An Alternative Path?</h5>

<p>One alternative could be using AI to help people connect with each other rather than replacing human relationships entirely. Imagine a system like Tinder, but instead of just swiping, it uses AI to match people based on real compatibility. This AI-assisted introduction could help bridge the loneliness gap without replacing the need for real human connection. But even here, there are risks. Much like dating apps today, these systems would still be driven by profit, and their business models are not aligned with fostering long-term relationships. Once users find a partner, they leave the app, and the app loses revenue—creating a fundamental conflict of interest.</p>

<h5 id="conclusion-ai-is-not-the-solution-to-loneliness">Conclusion: AI is Not the Solution to Loneliness</h5>

<p>In conclusion, while AI companionship may seem like a short-term solution to loneliness, it is far more likely to deepen the problem in the long run. Without proper regulation, this industry could evolve into something deeply harmful, where emotional attachment is commodified and relationships are controlled by powerful corporations. The loneliness crisis is real, but AI is not the solution. It’s a path that leads further away from authentic human connection, and we need to be very cautious about where it takes us.</p>
</div>
      
  </div>
</section>
<div class="prev_next flex gap-8 justify-center flex-wrap mb-12 mt-auto pt-6 border-t clear-both"><a href="/news/solar_punk/" class="block w-fit py-3 px-6 border shadow-md hover:shadow-lg">← Federated Approaches to Data Challenges in Ethical AI</a><a href="/news/ai_governance_euvschina/" class="block w-fit py-3 px-6 border shadow-md hover:shadow-lg">Exploring Global AI Governance: Lessons from China for the EU →</a></div>
</main><script>
const clicableImages = document.querySelectorAll(".zoom_outer");
if (clicableImages.length > 0) {
  clicableImages.forEach((el) => {
    el.addEventListener("click", (e) => {
       e.currentTarget.classList.toggle("wide_image")
    })
    }
  );
}
</script>
</body><footer class="footer p-9 bg-sky-200 dark:bg-slate-950 dark:text-sky-50 ">
    <div class="container">
        <p class="text-center">&copy; Copyright 2024, All right Reserved By - Nicolo' Brandizzi</p>
    </div>
</footer></html>