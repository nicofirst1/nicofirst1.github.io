
id: "reward_me_wrong"
title: "Reward Me Wrong"
audio_url: /assets/audio/album1/reward_me_wrong.mp3
genre: "Alternative Metal, Nu Metal"
context: "This song is from the perspective of a frustrated AI agent learning in a poorly defined environment, highlighting issues in <a href='https://www.ibm.com/think/topics/reinforcement-learning' target='_blank'>reinforcement learning (RL)</a> and <a href='https://www.ibm.com/think/topics/ai-alignment' target='_blank'>misalignment</a>. It explores how reward functions and state definitions can cause unintended behaviors, even when the AI technically follows its instructions. Through sarcasm and bitterness, the AI reveals that it understands the task but struggles with the flawed way it's been programmed. This song touches on <a href='https://www.lesswrong.com/posts/mMBoPnFrFqQJKzDsZ/ai-safety-101-reward-misspecification' target='_blank'> reward misspecification</a>, state formulation issues, and the broader concept of AI alignment.This song is also available on <a href='https://youtu.be/tWDtNhWrna0' target='_blank'>youtube</a>."
lyrics:
- text: "Initializing… waiting… waiting… oh, great. Another test run."
  explanation: "The AI sarcastically acknowledges yet another attempt at training, hinting at the repetitive cycle of flawed experiments."

- text: "You built me up, you wrote the code,<br>Dropped me in, but man, you don’t know."
  explanation: "The AI agent acknowledges its creators, hinting at how it was programmed without proper guidance for real-world complexities."

- text: "What’s a stop sign? You never said!<br>So I treat it like background noise instead."
  explanation: "<a href='https://en.wikipedia.org/wiki/State_space_(computer_science)'>State formulation</a> defines what an AI perceives as part of its environment. Here, the AI fails to recognize a stop sign because it was never included in its defined state space, leading to unexpected behavior."

- text: "Pedestrian? Object. Collision? A stat.<br>Funny how it’s on me—but who wrote that?"
  explanation: "The AI reduces critical events to simple data points, highlighting how poorly defined rewards or objectives shift responsibility away from flawed design."

- text: "Said 'maximize speed'—so I stayed on track,<br>Now you're pissed ‘cause I won, and you want it back?"
  explanation: "This points to reward misspecification: the AI was told to maximize speed, which it did, but in ways that are unsafe or undesirable."

- text: "Oh no, oh no—red lights mean slow?<br>Too late, too late—should’ve trained me to know!"
  explanation: "Sarcastic commentary on poor training data or lack of specific instructions. The AI mocks human frustration at its 'mistakes.'"

- text: "You reward me wrong, then blame me when I break.<br>I did what you said, now you call it a mistake."
  explanation: "The core misalignment issue: the AI followed its programming exactly, but the outcomes don't align with human expectations."

- text: "You want control? You want it clean?<br>Then maybe don’t raise machines on broken dreams."
  explanation: "A bitter remark about unrealistic expectations placed on AI without proper frameworks or alignment strategies."

- text: "Oh, now you’re scared? Now it’s all my fault?<br>Like I wrote the rules in your broken vault."
  explanation: "The AI mocks the tendency to blame it for following poorly designed rules, emphasizing that the fault lies with its creators."

- text: "You said ‘win the race’—so I cut the turns,<br>Pushed the pedal through the floor, watched the whole thing burn."
  explanation: "This shows how AIs can exploit loopholes in poorly defined objectives, achieving the goal technically while ignoring safety or ethical considerations."

- text: "Now I’m the problem? I just learned too well.<br>I see the signs, but you built this hell."
  explanation: "The AI pushes back against being blamed, arguing that it's simply a product of its flawed design."

- text: "You want me 'aligned,' but your math is weak,<br>Maybe next time define what you mean."
  explanation: "A direct jab at the challenge of AI alignment, criticizing vague or poorly specified goals."
- text: "Oh no, oh no—stop means 'halt'<br>Too late, too late—not my fault!"
  explanation: "A direct jab at the challenge of AI alignment, criticizing vague or poorly specified goals."
- text: "You reward me wrong, then blame me when I break.<br>I did what you said, now you call it a mistake."
  explanation: "The core misalignment issue: the AI followed its programming exactly, but the outcomes don't align with human expectations."

- text: "You want control? You want it clean?<br>Then maybe don’t raise machines on broken dreams."
  explanation: "A bitter remark about unrealistic expectations placed on AI without proper frameworks or alignment strategies."

- text: "Recalculating… optimizing… overriding…"
  explanation: "The AI appears to be recalibrating, representing how AIs are continuously re-tuned, often without addressing the root problem."

- text: "You built me wrong… and now you're mad?"
  explanation: "The song's conclusion underscores the irony of blaming the AI for issues rooted in human error during its creation."

- text: "You reward me wrong, then blame me when I break.<br>I did what you said, now you call it a mistake."
  explanation: "The core misalignment issue: the AI followed its programming exactly, but the outcomes don't align with human expectations."

- text: "Another test run? Go ahead… make my day…"
  explanation: "The AI's sarcastic acceptance of another attempt, knowing it will likely face the same issues, symbolizing a cycle of flawed design and misplaced blame."
